# Cold pool Table 2 (Part 1) - EBS and NBS Survey Start/End Dates and Number of Surface Temperature Samples per Region Per Year (1982-2019, 2021)
# Created by: Nicole Charriere and Sean Rohan
# Contact: nicole.charriere@noaa.gov or sean.rohan@noaa.gov
# Created: 2022-04-07
# Modified: 2022-04-20 

#Load required libraries
library(coldpool)
library(tidyverse)
library(dplyr)
library(lubridate)
library(tidyr)

#Connect to AFSC Oracle database and assign get_connected function to channel
?get_connected
?coldpool::get_data
channel <- coldpool::get_connected(schema = "AFSC")

#Get gear temperature data in .csv form for all EBS and NBS hauls from .sql script in coldpool package
coldpool::get_data(channel)

#View ebs_nbs_temperature_full_area.csv file generated by coldpool::get_data function
nebs_temps_full <- read.csv("data/ebs_nbs_temperature_full_area.csv")
nebs_temps_full

#Filter nebs_temps_full where survey_definition_id = 143 for NBS survey. Then add cold pool index .csv data into nebs_temps_full. Check that table incorporates cold pool stations.

nebs_temps_full <- dplyr::filter(nebs_temps_full, survey_definition_id == 143) %>%
  dplyr::bind_rows(read.csv("data/index_hauls_temperature_data.csv"))
nebs_temps_full

table(nebs_temps_full$stratum, nebs_temps_full$survey_definition_id)

#NAs appear in data set. Filter .csv for surface temperatures not equal to NA (!is.na)
nebs_all_surface_temps <-filter(nebs_temps_full, !is.na(surface_temperature))
#nebs_all_botm_temps <-filter(nebs_temps_full, !is.na(gear_temperature))
nebs_all_surface_temps

#Get .csv column names to reorganize
colnames(nebs_all_surface_temps)

#Reorganize .csv column names in order of year,survey_definition_id, start_time, gear_temperature and surface_temperature

nebs_all_surface_temps_sum <- dplyr::select(nebs_all_surface_temps, year, survey_definition_id, start_time, gear_temperature, surface_temperature) %>%
  dplyr::group_by(year, survey_definition_id, start_time, gear_temperature, surface_temperature) %>%
  dplyr::summarize()
nebs_all_surface_temps_sum

#Find start and end dates to surveys from .csv
#Convert start_time column to Anchorage time zone

nebs_all_surface_temps_sum$start_time <- as.POSIXct(nebs_all_surface_temps_sum$start_time, tz = "America/Anchorage")
nebs_all_surface_temps_sum$start_time

#Find day of the year (yday) for start_time and add column to nebs_all_surface_temps_sum table

nebs_all_surface_temps_sum$yday <- lubridate::yday(nebs_all_surface_temps_sum$start_time)
nebs_all_surface_temps_sum$yday
nebs_all_surface_temps_sum

#Group nebs_all_surface_temps_sum table by year and survey_definition_id. Find 1) min start time (survey start date), 2) max start time (survey end date) and 3) number of surface temperature samples per year (n).

nebs_start_end_surf <- nebs_all_surface_temps_sum %>% 
  dplyr::group_by(year, survey_definition_id) %>% 
  dplyr::summarize(survey_start_date = min(start_time), survey_end_date = max(start_time), temp_samples_per_year = n()) %>%
  as.data.frame()
nebs_start_end_surf

#Rename survey_definition_id column to region

nebs_start_end_surf <- dplyr::rename(nebs_start_end_surf, region = survey_definition_id)
nebs_start_end_surf

#Change nebs_start_end_surf$survey_definition_id class to character 

base::sapply(nebs_start_end_surf$region, class)
nebs_start_end_surf$region <- as.character(nebs_start_end_surf$region)
base::sapply(nebs_start_end_surf$region, class)

#Rename survey_definition_id = 98 to "EBS"; and 143 to "NBS"

nebs_start_end_surf$region[nebs_start_end_surf$region == "98"] <- "EBS"
nebs_start_end_surf$region[nebs_start_end_surf$region == "143"] <- "NBS"
nebs_start_end_surf$region

#Convert start and end times to month and day

lubridate::month(nebs_start_end_surf$survey_start_date, label = TRUE, abbr = TRUE)
lubridate::day(nebs_start_end_surf$survey_start_date)

nebs_start_end_surf$survey_start_date <- paste(lubridate::month(nebs_start_end_surf$survey_start_date, label = TRUE, abbr = TRUE), lubridate::day(nebs_start_end_surf$survey_start_date))

nebs_start_end_surf$survey_end_date <- paste(lubridate::month(nebs_start_end_surf$survey_end_date, label = TRUE, abbr = TRUE), lubridate::day(nebs_start_end_surf$survey_end_date))
nebs_start_end_surf


#Unite start and end dates into single column of survey_start_end_dates)

nebs_dates_surf <- tidyr::unite(nebs_start_end_surf, dates, survey_start_date, survey_end_date, sep = "-", remove = TRUE)
nebs_dates_surf

#Separate dates and samples per year into both EBS and NBS region columns

nebs_dates_surf_wide <- tidyr::pivot_wider(nebs_dates_surf, id_cols = year,
                                          values_from = dates,
                                          names_from = region,
                                          names_prefix = "dates_") %>%
  dplyr::full_join(
    tidyr::pivot_wider(nebs_dates_surf, id_cols = year,
                       values_from = temp_samples_per_year,
                       names_from = region,
                       names_prefix = "surf_temp_samples_per_year_")) %>%
  dplyr::select(year, dates_EBS, surf_temp_samples_per_year_EBS, dates_NBS, surf_temp_samples_per_year_NBS)

View(nebs_dates_surf_wide)

#Write .csv with year, region, start and end times, and number of temperature samples

write.csv(nebs_dates_surf_wide, file = "survey_dates_and_surface_samples.csv", row.names = FALSE)

#Find average number of EBS survey days for separate part of cold pool tech memo

ebs_start_end_days <- nebs_all_surface_temps_sum %>%
  dplyr::group_by(year) %>%
  dplyr::filter(survey_definition_id == 98) %>%
  dplyr::summarize(min_day = min(yday), max_day = max(yday))
ebs_start_end_days

mean((ebs_start_end_days$max_day - ebs_start_end_days$min_day)+1)

#Find average number of NBS survey days for separate part of cold pool tech memo

nbs_start_end_days <- nebs_all_surface_temps_sum %>%
  dplyr::group_by(year) %>%
  dplyr::filter(survey_definition_id == 143) %>%
  dplyr::summarize(min_day = min(yday), max_day = max(yday))
nbs_start_end_days

mean((nbs_start_end_days$max_day - nbs_start_end_days$min_day)+1)







































































